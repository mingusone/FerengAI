{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas_datareader import data\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://ming:ming123@ferengai-tiysn.mongodb.net/test?retryWrites=true&w=majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What stocks do we want?\n",
    "stocks = [\"MSFT\",\"AMZN\",\"GOOG\"]\n",
    "\n",
    "for stock in stocks:\n",
    "    # This is some magic stuff. It just works because Pandas devs are smart.\n",
    "    start = datetime.datetime(1980,1,1)\n",
    "    end = datetime.datetime(2019,12,31)\n",
    "    stock_df = data.DataReader(stock, 'yahoo', start, end)\n",
    "    \n",
    "    # Write the data to a CSV so we have a hard copy of the data\n",
    "    stock_df.to_csv(f'../resources/{stock}_data.csv')\n",
    "\n",
    "    # This will turn the date column from index to actual column of data\n",
    "    # As well as reset column names into single words instead of multidimensional\n",
    "    stock_df.reset_index(inplace=True)\n",
    "\n",
    "    # Get the mongoDB variables ready\n",
    "    db = client[stock]\n",
    "    col = db.cleaned\n",
    "    upload = stock_df.to_dict('records')\n",
    "    \n",
    "    # Always drop the old collection before uploading new one.\n",
    "    # Otherwise the collection keeps growing with duplicate data.\n",
    "    # Unlike SQL, mongo does not check for duplicates. There is no primary key column\n",
    "    # Just a randomly generated object_ID for every single new row.\n",
    "    col.drop()\n",
    "    col.insert(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
